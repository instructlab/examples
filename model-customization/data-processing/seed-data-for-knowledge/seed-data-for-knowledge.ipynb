{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b320d737-0c9c-4023-8959-d4f816b5deac",
   "metadata": {},
   "source": [
    "# Seed Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f9ebd-bafe-4439-b984-cd2ff0e47050",
   "metadata": {},
   "source": [
    "## Contribution Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44999da4-6541-4076-8d1e-a53536fee292",
   "metadata": {},
   "source": [
    "### What is a Contribution?\n",
    "\n",
    "To add knowledge to a model, a user groups source documents of that contain the knowledge into knowledge contributions. A knowledge contribution is made up of:\n",
    "\n",
    "1. One or more PDF documents that can be described by a contribution summary.\n",
    "2. A contribution summary.\n",
    "3. A contribution domain.\n",
    "4. A unique name used to create a directory in the workspace for artifacts created by each step for the contribution.\n",
    "\n",
    "Once contributions are set up a user can go through the data pre-processing workflow.\n",
    "\n",
    "### What is a Contribution Summary?\n",
    "\n",
    "In the synthetic data generation step, a model (known as the teacher model) generates synthetic data based on the source document.\n",
    "The contribution summary and domain are used in the prompts that are sent to the teacher model to create data.\n",
    "\n",
    "The document gets broken up into [chunks](#Chunking), and each chunk is in the prompt sent to the teacher model.\n",
    "The contribution summary provides additional context to each chunk of a source document ensuring the teacher model has necessary background information.\n",
    "\n",
    "Contribution summaries should be specific, avoid acronyms or other vague references, and the represent the documents focus areas.\n",
    "When a contribution includes many versions of the same document, publication dates, volume numbers, or any other identifiers to distinguish between versions should be included in the contribution summary.\n",
    "\n",
    "Here is an example of a contribution summary from a recent paper on [inference-time scaling](https://arxiv.org/pdf/2502.01618):\n",
    "\n",
    "```\n",
    "\"A Probabilistic Inference Approach to Inference-Time Scaling of Large Language Models (LLMs)\"\n",
    "```\n",
    "\n",
    "Since the title of the paper does a good job summaraizing the paper, the summary is based off the title but with the acronym LLM spelled out. \n",
    "\n",
    "Usually contributions only have one document. Contributions with multiple documents happen when the subject matter and format are similar among a group of documents. \n",
    "\n",
    "An example of a contribution having multiple documents would be the desire to teach a model an organization's bylaws over the years 2021, 2022, 2023, 2024, with a different PDF for each year.\n",
    "\n",
    "A contribution summary in this case might look like:\n",
    "\n",
    "`Bylaws of organization Foo from 2021 - 2024`\n",
    "\n",
    "In the case that there was only one source document from the year 2023, the contribution summary would be:\n",
    "\n",
    "`2023 Bylaws of organization Foo`\n",
    "\n",
    "Another example of having multiple documents within the same contribution would be if the documents had the same format. An example here could be grouping together a furniture company's instruction manuals. The format and layout of the instruction manuals would be the same across different pieces of furniture, but each manual covers different furniture.\n",
    "\n",
    "`Furniture company Foo's assembly instructions for tables, desks, and nightstands`\n",
    "\n",
    "If the contribution only contained a PDF for the assembly instructions for an oak dining table the summary would be:\n",
    "\n",
    "`Assembly instructions for furniture company Foo's oak dining table`\n",
    "\n",
    "### What is a Contribution Domain?\n",
    "\n",
    "A contribution's domain is the overarching subject or scope of the source document(s). The domain provides critical context to guide the teacher model in generating synthetic data that is relevant and grounded.\n",
    "\n",
    "The domain is brief and should not exceed 3 words, but should ideally be 1-2 words.\n",
    "\n",
    "To determine the domain, users should review document's primary subject and identify the main topic or purpose of the document.\n",
    "Consider the intended use of the document and align it with the use case or audience. E.g. a tech manual for developers might fall under the “software development” domain.\n",
    "\n",
    "For the contribution summary examples discussed in the previous sections, domains could be `Artificial Intelligence Research`, `Bylaws`, and `Furniture Assembly`.\n",
    "\n",
    "**Note:** Different contributions can have the same domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c1a67-2c29-468a-857b-aaaa15659a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Populated later on\n",
    "contributions = []\n",
    "WORKSPACE_DIR = Path(\"data/sample-contributions\")\n",
    "\n",
    "# Inference Time Scaling Contribution\n",
    "contribution_name = \"inference-time-scaling\"\n",
    "contribution_domain = \"Artificial Intelligence Research\" \n",
    "contribution_summary = \"A Probabilistic Inference Approach to Inference-Time Scaling of Large Language Models (LLMs)\"\n",
    "\n",
    "# Add contribution information to the knowledge_contribution dictionary for it\n",
    "knowledge_contribution = {\"name\": contribution_name, \"domain\": contribution_domain, \"summary\": contribution_summary}\n",
    "contributions.append(knowledge_contribution)\n",
    "\n",
    "# NFL Rules Contribution\n",
    "contribution2_name = \"nfl\"\n",
    "contribution2_domain = \"sports rules\" \n",
    "contribution2_summary = \"Official playing rules of the National Football League 2022, 2023\"\n",
    "knowledge_contribution2 = {\"name\": contribution2_name, \"domain\": contribution2_domain, \"summary\": contribution2_summary}\n",
    "contributions.append(knowledge_contribution2)\n",
    "\n",
    "for contribution in contributions:\n",
    "    contribution_dir = WORKSPACE_DIR / contribution[\"name\"]\n",
    "    contribution[\"dir\"] = contribution_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3b1bc-84b7-483c-910d-4983e94fe3c2",
   "metadata": {},
   "source": [
    "To create contributions, define the `name` for the contribution, and the `domain` and `summary`. The `name`, `domain` and `summary` go into a dictionary called `knowledge_contribution` which gets added to a list called `contributions`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109090af-c01d-494f-8dde-0daddcdb3cc8",
   "metadata": {},
   "source": [
    "## Seed Data Creation\n",
    "\n",
    "To start the synthetic data generation process, users need to prepare a diverse set of questions and answers based off chunks from each source document. A chunk and question-and-answer pairs are called a seed example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c41ed1-1d96-4388-9afe-ab40efd0c717",
   "metadata": {},
   "source": [
    "### Install docling-sdg\n",
    "\n",
    "[Docling-sdg](https://github.com/docling-project/docling-sdg) project is used to generate question and answer pairs for seed examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1fd21-faab-4dbb-9217-191e02088678",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq docling-sdg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3b8ce4-8e5e-4fe2-8063-bfa9c6c1ee30",
   "metadata": {},
   "source": [
    "### Select the chunks for the seed examples\n",
    "\n",
    "Chunks for seed examples should be diverse in style. These can be selected by hand or selecting diverse chunks from all of the chunks using the [subset selection notebook](https://github.com/instructlab/examples/blob/main/notebooks/instructlab-knowledge/subset-selection.ipynb).\n",
    "\n",
    "If users are selecting chunks by hand, chunks should be taken directly from lines in `chunks.jsonl`. These lines have `chunk`, `file`, and `metadata` fields for each entry.\n",
    "\n",
    "The below code randomly selects a preset number of chunks and saves them in a jsonl file for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369167a-a4c7-4e28-8d0b-036c9e9f101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.qna_gen import save_random_chunk_selection\n",
    "\n",
    "NUM_SEED_EXAMPLES = 7\n",
    "\n",
    "for contribution in contributions:\n",
    "    chunks_jsonl_path = contribution[\"dir\"] / \"chunks.jsonl\"\n",
    "    output_dir = contribution[\"dir\"]\n",
    "\n",
    "    selected_chunks_jsonl = save_random_chunk_selection(chunks_jsonl_path,\n",
    "                           output_dir,\n",
    "                           NUM_SEED_EXAMPLES)\n",
    "    print(f\"selected_chunks.jsonl saved to: {selected_chunks_jsonl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e33660-1541-4733-a2b8-4cd9a18ddff0",
   "metadata": {},
   "source": [
    "### Initialize QA generator model & Number of Seed examples\n",
    "\n",
    "To generate seed examples you need to set: \n",
    "1. The the Open AI compatible endpoint for the model generating question and answer pairs. This endpoint can be local or remote.\n",
    "2. The model's API key\n",
    "3. The model's name\n",
    "4. The number of seed examples you wish to generate for each contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de0a98-9985-4c0e-a628-74b6651e9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "API_KEY = os.getenv(\"MODEL_API_KEY\") or \"\"  # the API access key for your account (cannot be empty)\n",
    "ENDPOINT_URL = os.getenv(\"MODEL_ENDPOINT_URL\") or \"\" # the URL of your model's API. URL can end in \"/v1\"\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\") or \"mistralai/Mixtral-8x7B-Instruct-v0.1\" # the name of your model\n",
    "NUM_SEED_EXAMPLES = 7 # number of seed examples set to 7 so that users have options to pick 5 from they like the most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da76292-f3ca-4732-a2cd-16dba110debe",
   "metadata": {},
   "source": [
    "#### [OPTIONAL] Prompt customization for Q&A Generation\n",
    "\n",
    "Optionally insert your own stylistic customization statement below. If `customization_str` is `None`, there will be no customization attempted and the default QA generation prompt will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7a32a-e82a-4b48-a0ad-a5ff16eb9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_str = None \n",
    "\n",
    "# Example: \n",
    "# customization_str = \"Write at the fifth grade level.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950551c4-790f-4c5e-9c17-85291e8300b3",
   "metadata": {},
   "source": [
    "#### Generate questions and answers and create qna.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af93d9-368d-44bc-ba39-5a5e1fa98b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.qna_gen import generate_seed_examples\n",
    "\n",
    "for contribution in contributions:\n",
    "    output_dir = contribution[\"dir\"]\n",
    "    selected_chunks_path = contribution[\"dir\"] / \"selected_chunks.jsonl\"\n",
    "\n",
    "    qna_output_path = generate_seed_examples(contribution[\"name\"],\n",
    "                           selected_chunks_path,\n",
    "                           output_dir,\n",
    "                           API_KEY,\n",
    "                           ENDPOINT_URL,\n",
    "                           MODEL_NAME,\n",
    "                           contribution[\"domain\"],\n",
    "                           contribution[\"summary\"],                  \n",
    "                           customization_str)\n",
    "    print(f\"qna.yaml saved to: {qna_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f89e4-be49-4ecd-b0e5-445864d250a3",
   "metadata": {},
   "source": [
    "### Review and Revise Seed Examples\n",
    "\n",
    "A quality set of seed examples has diverse contexts and question-and-answer pairs across every seed example. You can asses the `qna.yaml` files in your preferred text editor to ensure the quality, diversity, and style of generated questions and answers, and modify them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5db2f7-840d-488e-b841-149013367ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.qna_gen import view_seed_example\n",
    "\n",
    "index = 0 # index of seed example to view. Value must be lower than number of seed examples\n",
    "\n",
    "# pass in path to qna.yaml file and seed example index to view single seed example\n",
    "view_seed_example(qna_output_path, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec1275-2f1a-4625-8d58-b8f685c3ccc0",
   "metadata": {},
   "source": [
    "After assessment, the `qna.yaml` files can be quickly reviewed to ensure they includes the required elements and correct number of each. It is recommended to have at least 5 seed examples. Each seed example must have 3 question and answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fb3dc-5d34-4441-8046-1af9d4cd605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.qna_gen import review_seed_examples_file\n",
    "\n",
    "for contribution in contributions:\n",
    "        qna_path = contribution[\"dir\"] / \"qna.yaml\"\n",
    "        review_seed_examples_file(qna_path, min_seed_examples=5, num_qa_pairs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24be75-085f-4949-96f6-a8e15f081e72",
   "metadata": {},
   "source": [
    "## Create Seed Dataset for SDG\n",
    "\n",
    "This step creates the seed data for SDG. This data is a JSON file that contains a combination of the `seed_examples` in the `qna.yaml` and the chunks from the source document. \n",
    "\n",
    "Intermediate seed data files are created for each contribution with the contribution's name included in the file name. For example for the `nfl` contribution, a file containing seed data called `seed_data-nfl.jsonl`. This file contains a combination of all of the chunks from the NFL source documents and the seed examples in the `qna.yaml` for `nfl`.\n",
    "\n",
    "After seed data files are created for each contribution, a final `seed_data.jsonl`. This file is a concatenation of all of the intermediate `seed_data-{contribution name}.jsonl` files and should be used as an input to SDG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b588ec4-e929-43ff-91ce-79a04352b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12c859-e4fb-4185-a65a-33347d773d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.create_seed_dataset import get_seed_dataset, safe_concatenate_datasets\n",
    "\n",
    "contribution_datasets = []\n",
    "for contribution in contributions:\n",
    "    chunks_dir = contribution[\"dir\"]\n",
    "    qna_dir = contribution[\"dir\"]\n",
    "    seed_data = get_seed_dataset(chunks_dir, qna_dir)\n",
    "    output_path = f'{contribution_dir}/seed_data-{contribution_name}.jsonl'\n",
    "    seed_data.to_json(output_path, orient='records', lines=True)\n",
    "    contribution_datasets.append(seed_data)\n",
    "    print(f\"Intermediate results saved to: {output_path}\")\n",
    "\n",
    "final_seed_data = safe_concatenate_datasets(contribution_datasets)\n",
    "output_path = f'{WORKSPACE_DIR}/seed_data.jsonl'\n",
    "final_seed_data.to_json(output_path, orient='records', lines=True)\n",
    "\n",
    "print(f\"Final seed data contains {final_seed_data.data.num_rows} rows\")\n",
    "print(f\"Final seed data for SDG saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a0935-11fc-48a4-8866-f9376ebb01fb",
   "metadata": {},
   "source": [
    "### Inspect the seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1aa362-221a-4a40-b49b-b729194ebf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed_data.data.table.slice(length=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
